{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"},"kaggle":{"accelerator":"none","dataSources":[],"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"from tensorflow.keras.layers import Layer, GlobalAveragePooling2D, Conv1D, Multiply, Reshape, Add, Conv2D, BatchNormalization, Activation, Dense, Dropout\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.models import Model, load_model\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.callbacks import ModelCheckpoint, ReduceLROnPlateau\nimport keras\nimport tensorflow as tf\nimport os\nfrom tensorflow.keras.layers import Conv2D, MaxPooling2D, Activation, Lambda, GlobalAveragePooling2D, Dense, Add, Input, BatchNormalization  # Add BatchNormalization here\nfrom tensorflow.keras.applications import InceptionResNetV2\n\n\n@keras.saving.register_keras_serializable()\nclass ECALayer(Layer):\n    def __init__(self, k_size=32, **kwargs):\n        super(ECALayer, self).__init__(**kwargs)  # Pass **kwargs to parent class\n        self.k_size = k_size\n\n    def build(self, input_shape):\n        self.global_avg_pool = GlobalAveragePooling2D()\n        self.conv1d = Conv1D(1, kernel_size=self.k_size, padding='same', use_bias=False)\n\n    def call(self, inputs):\n        # Global Average Pooling\n        x = self.global_avg_pool(inputs)\n        x = tf.expand_dims(x, axis=-1)  # Expand dims for Conv1D\n        x = self.conv1d(x)  # Apply Conv1D for channel attention\n        x = tf.keras.activations.sigmoid(x)\n        x = tf.squeeze(x, axis=-1)  # Squeeze back the extra dimension\n        x = Multiply()([inputs, x])  # Multiply attention with the input\n        return x\n\n# HFE Block \ndef conv_module(x, k):\n    a = Conv2D(k, (1, 1), padding='same')(x)\n    a = BatchNormalization()(a)\n    a = Activation('swish')(a)\n\n    y = Conv2D(k // 2, (3, 3), padding='same')(x)\n    y = BatchNormalization()(y)\n    y = Activation('swish')(y)\n    y = Conv2D(k // 2, (3, 3), padding='same')(y)\n    y = BatchNormalization()(y)\n    y = Activation('swish')(y)\n\n    z = Conv2D(k, (3, 3), padding='same')(x)\n    z = BatchNormalization()(z)\n    z = Activation('swish')(z)\n\n    c = tf.keras.layers.Concatenate()([y, z])\n    d = Conv2D(k, (3, 3), padding='same')(c)\n    d = BatchNormalization()(d)\n    d = Activation('swish')(d)\n\n    x = tf.keras.layers.Concatenate()([d, c])\n    x = tf.keras.layers.Concatenate()([x, a])\n    x = Conv2D(k, (1, 1), padding='same')(x)\n    x = BatchNormalization()(x)\n    x = Activation('swish')(x)\n\n    return x\n\n# Data augmentation for the training set\ntrain_data = ImageDataGenerator(\n    rescale=1./255,\n    rotation_range=15,  # Â±15 degrees\n    width_shift_range=0.1,  # Horizontal shift\n    height_shift_range=0.1,  # Vertical shift\n    shear_range=0.1,  # Shear intensity\n    zoom_range=[0.8, 1.2],  # Zoom range: 80% to 120%\n    fill_mode='nearest',  # Fill mode for empty pixels\n    horizontal_flip=True,\n)\n\n# No augmentation for validation/test sets, just rescaling\ntest_data = ImageDataGenerator(rescale=1./255)\n\n# Load train, validation, and test sets using flow_from_directory\ntrain_data = train_data.flow_from_directory(\n    train_folder,\n    target_size=(224, 224),\n    batch_size=20,\n    color_mode='rgb',\n    shuffle=True,\n    class_mode='categorical'\n)\n\n\ntest_data = test_data.flow_from_directory(\n    test_folder,\n    target_size=(224, 224),\n    batch_size=20,\n    color_mode='rgb',\n    shuffle=False,\n    class_mode='categorical'\n)\n\n# Add Your Developed Inception-ResNet (i.e., Or you can use the pretrained one as follows)\ninceptionresnet_base = InceptionResNetV2(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n\n# Build the model\nx = inceptionresnet_base.output\nx = conv_module(x, 32)\nx = ECALayer()(x)  # Apply ECA block\nx = conv_module(x, 64)\nx = ECALayer()(x)  # Apply ECA block\n# Global pooling\nx = GlobalAveragePooling2D()(x)\n# Fully connected layer with 128 units\nx = Dense(128, activation='relu')(x)\n# Output layer for your number of classes (replace 2 with the number of output classes)\noutput = Dense(2, activation='softmax')(x)\n\n# Define the complete model\nmodel = Model(inputs=densenet_base.input, outputs=output)\n\n# Compile the model\nmodel.compile(optimizer=Adam(learning_rate=0.0001), loss='categorical_crossentropy', metrics=['accuracy'])\n\n# Callbacks for reducing learning rate and saving the best model\nreduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=2, min_lr=1e-6)\nmodel_checkpoint = ModelCheckpoint(\"model.keras\", save_best_only=True, monitor='val_loss')\n\n# Model Training\nhistory = model.fit(\n    train_data,\n    epochs=20,\n    validation_data=test_data,\n    callbacks=[reduce_lr, model_checkpoint]\n)\n\n# Saving the model\nmodel.save(\"model.keras\")\n\n# Loading the model (with custom objects)\nloaded_model = load_model(\"model.keras\", custom_objects={'ECALayer': ECALayer})\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"outputs":[],"execution_count":null}]}